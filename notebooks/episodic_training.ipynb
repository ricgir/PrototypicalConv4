{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQLsAJC01D5m",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Train a model with Episodic Training\n",
        "Episodic training has attracted a lot of interest in the early years of Few-Shot Learning research. Some papers still use it, and refer to it as \"meta-learning\".\n",
        "\n",
        "Recent works distinguish the Few-Shot Classifier from the training framework, so as from v1.0 of EasyFSL, methods to episodically train a classifier were taken out of the logic of the FewShotClassifier class. Instead, we provide in this notebook an example of how to perform episodic training on a few-shot classifier.\n",
        "\n",
        "Use it, copy it, change it, get crazy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5aFVwdT1D5t",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Getting started\n",
        "First we're going to do some imports (this is not the interesting part)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: Replace the token with your actual, current token if you generate a new one.\n",
        "# This token is for demonstration only.\n",
        "! export KAGGLE_USERNAME=\"richathakwani\"\n",
        "! export KAGGLE_KEY=\"KGAT_8ed46d003f4c9135fdf7081597a8cc00\"\n",
        "\n",
        "# Alternatively, and often more effective in Colab for setting a persistent env variable:\n",
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"richathakwani\"\n",
        "os.environ['KAGGLE_KEY'] = \"KGAT_8ed46d003f4c9135fdf7081597a8cc00\""
      ],
      "metadata": {
        "id": "NfVqlZxjB-Mk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"arjunashok33/miniimagenet\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4GxDt-nDH3b",
        "outputId": "87a2bb97-cacd-431f-a581-2e8c9f17dd4c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'miniimagenet' dataset.\n",
            "Path to dataset files: /kaggle/input/miniimagenet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This unzips the file and creates a new directory named 'miniimagenet'\n",
        "! unzip -q miniimagenet.zip -d kaggle/input/miniimagenet\n",
        "\n",
        "# Verify the files are there (optional)\n",
        "! ls /kaggle/input/miniimagenet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp31jqEECjwF",
        "outputId": "62bf5267-d0b9-4bf5-e28f-3aba70b22a3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open miniimagenet.zip, miniimagenet.zip.zip or miniimagenet.zip.ZIP.\n",
            "n01532829  n02101006  n02174001  n03047690  n03544143  n04149813  n04612504\n",
            "n01558993  n02105505  n02219486  n03062245  n03584254  n04243546  n06794110\n",
            "n01704323  n02108089  n02443484  n03075370  n03676483  n04251144  n07584110\n",
            "n01749939  n02108551  n02457408  n03127925  n03770439  n04258138  n07613480\n",
            "n01770081  n02108915  n02606052  n03146219  n03773504  n04275548  n07697537\n",
            "n01843383  n02110063  n02687172  n03207743  n03775546  n04296562  n07747607\n",
            "n01855672  n02110341  n02747177  n03220513  n03838899  n04389033  n09246464\n",
            "n01910747  n02111277  n02795169  n03272010  n03854065  n04418357  n09256479\n",
            "n01930112  n02113712  n02823428  n03337140  n03888605  n04435653  n13054560\n",
            "n01981276  n02114548  n02871525  n03347037  n03908618  n04443257  n13133613\n",
            "n02074367  n02116738  n02950826  n03400231  n03924679  n04509417\n",
            "n02089867  n02120079  n02966193  n03417042  n03980874  n04515003\n",
            "n02091244  n02129165  n02971356  n03476684  n03998194  n04522168\n",
            "n02091831  n02138441  n02981792  n03527444  n04067472  n04596742\n",
            "n02099601  n02165456  n03017168  n03535780  n04146614  n04604644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5qn7ZpjCPV0",
        "outputId": "6097b3aa-ddda-49a2-d403-2e87a0c86bb6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p ./data/mini_imagenet/images"
      ],
      "metadata": {
        "id": "ZFkISIuTFjTH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /kaggle/input/miniimagenet/* data/mini_imagenet/images/"
      ],
      "metadata": {
        "id": "EuEn-LZ6FNQG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/sicara/easy-few-shot-learning/master/data/mini_imagenet/train.csv -O ./data/mini_imagenet/train.csv\n",
        "!wget https://raw.githubusercontent.com/sicara/easy-few-shot-learning/master/data/mini_imagenet/val.csv -O ./data/mini_imagenet/val.csv\n",
        "!wget https://raw.githubusercontent.com/sicara/easy-few-shot-learning/master/data/mini_imagenet/test.csv -O ./data/mini_imagenet/test.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSkclFxnHfN9",
        "outputId": "c445ad53-4ad6-4996-ceab-74ea2ee02358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-22 06:42:55--  https://raw.githubusercontent.com/sicara/easy-few-shot-learning/master/data/mini_imagenet/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1166529 (1.1M) [text/plain]\n",
            "Saving to: â€˜./data/mini_imagenet/train.csvâ€™\n",
            "\n",
            "\r          ./data/mi   0%[                    ]       0  --.-KB/s               \r./data/mini_imagene 100%[===================>]   1.11M  --.-KB/s    in 0.006s  \n",
            "\n",
            "2025-11-22 06:42:55 (184 MB/s) - â€˜./data/mini_imagenet/train.csvâ€™ saved [1166529/1166529]\n",
            "\n",
            "--2025-11-22 06:42:55--  https://raw.githubusercontent.com/sicara/easy-few-shot-learning/master/data/mini_imagenet/val.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 290868 (284K) [text/plain]\n",
            "Saving to: â€˜./data/mini_imagenet/val.csvâ€™\n",
            "\n",
            "./data/mini_imagene 100%[===================>] 284.05K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2025-11-22 06:42:56 (70.3 MB/s) - â€˜./data/mini_imagenet/val.csvâ€™ saved [290868/290868]\n",
            "\n",
            "--2025-11-22 06:42:56--  https://raw.githubusercontent.com/sicara/easy-few-shot-learning/master/data/mini_imagenet/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 364553 (356K) [text/plain]\n",
            "Saving to: â€˜./data/mini_imagenet/test.csvâ€™\n",
            "\n",
            "./data/mini_imagene 100%[===================>] 356.01K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2025-11-22 06:42:57 (60.9 MB/s) - â€˜./data/mini_imagenet/test.csvâ€™ saved [364553/364553]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "u-qkFjp9h4Mh",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    colab = True\n",
        "except:\n",
        "    colab = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QTwWMJerh5yF",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "3bac238f-b30c-4f43-b4a7-332f9fbb324d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'easy-few-shot-learning'...\n",
            "remote: Enumerating objects: 1201, done.\u001b[K\n",
            "remote: Counting objects: 100% (364/364), done.\u001b[K\n",
            "remote: Compressing objects: 100% (186/186), done.\u001b[K\n",
            "remote: Total 1201 (delta 255), reused 182 (delta 178), pack-reused 837 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1201/1201), 2.31 MiB | 30.72 MiB/s, done.\n",
            "Resolving deltas: 100% (723/723), done.\n",
            "/content/easy-few-shot-learning\n",
            "Processing /content/easy-few-shot-learning\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from easyfsl==1.5.0) (3.10.0)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from easyfsl==1.5.0) (2.2.2)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from easyfsl==1.5.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from easyfsl==1.5.0) (0.24.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from easyfsl==1.5.0) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->easyfsl==1.5.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->easyfsl==1.5.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->easyfsl==1.5.0) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->easyfsl==1.5.0) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->easyfsl==1.5.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->easyfsl==1.5.0) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->easyfsl==1.5.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->easyfsl==1.5.0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->easyfsl==1.5.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->easyfsl==1.5.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->easyfsl==1.5.0) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.5.0->easyfsl==1.5.0) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->easyfsl==1.5.0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.5.0->easyfsl==1.5.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.5.0->easyfsl==1.5.0) (3.0.3)\n",
            "Building wheels for collected packages: easyfsl\n",
            "  Building wheel for easyfsl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easyfsl: filename=easyfsl-1.5.0-py3-none-any.whl size=73036 sha256=3385a3ef2a9065eaa1da1cf5ba7888af1ec5c21125c7b3bc5e9945ebd3486b3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/4a/e4/04c53831c4746b4b14e1b1359663380e928f6ab9dddfbad300\n",
            "Successfully built easyfsl\n",
            "Installing collected packages: easyfsl\n",
            "Successfully installed easyfsl-1.5.0\n"
          ]
        }
      ],
      "source": [
        "if colab is True:\n",
        "    # Running in Google Colab\n",
        "    # Clone the repo\n",
        "    !git clone https://github.com/sicara/easy-few-shot-learning\n",
        "    %cd easy-few-shot-learning\n",
        "    !pip install .\n",
        "else:\n",
        "    # Run locally\n",
        "    # Ensure working directory is the project's root\n",
        "    # Make sure easyfsl is installed!\n",
        "    %cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "source": [
        "import copy\n",
        "from pathlib import Path\n",
        "import random\n",
        "from statistics import mean\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jPSnatlxDqCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we're gonna do the most important thing in Machine Learning research: ensuring reproducibility by setting the random seed. We're going to set the seed for all random packages that we could possibly use, plus some other stuff to make CUDA deterministic (see [here](https://pytorch.org/docs/stable/notes/randomness.html)).\n",
        "\n",
        "I strongly encourage that you do this in **all your scripts**."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "CUapEvwPDqCW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "source": [
        "random_seed = 0\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "random.seed(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vaXowGz6DqCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pwd"
      ],
      "metadata": {
        "id": "SxxJo8IqOURX",
        "outputId": "f9c837d9-b76c-49ff-f7e5-2a4e06fd9ce0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/easy-few-shot-learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we're gonna set the shape of our problem.\n",
        "\n",
        "Also we define our set-up, like the device (change it if you don't have CUDA) or the number of workers for data loading."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "aUBKSWr3DqCX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "source": [
        "n_way = 5\n",
        "n_shot = 5\n",
        "n_query = 10\n",
        "\n",
        "n_workers = 12"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "V6qynheyDqCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "First we define our data loaders for training and validation. You can see that I chose tu use CUB in this notebook, because it's a small dataset, so we can have good results quite quickly. We use `CUB` and `TaskSampler` which are built-in objects from EasyFSL."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "A777NFgdDqCZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Download the CUB dataset\n",
        "# !make download-cub"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zRO6ZNruDqCZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from easyfsl.datasets import MiniImageNet\n",
        "from easyfsl.samplers import TaskSampler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "n_tasks_per_epoch = 700\n",
        "n_validation_tasks = 200\n",
        "\n",
        "\n",
        "train_set = MiniImageNet(root=\"./data/mini_imagenet/data\", split=\"train\")\n",
        "val_set = MiniImageNet(root=\"./data/mini_imagenet/data\", split=\"val\")\n",
        "test_set = MiniImageNet(root=\"./data/mini_imagenet/data\", split=\"test\")\n",
        "\n",
        "# Those are special batch samplers that sample few-shot classification tasks with a pre-defined shape\n",
        "train_sampler = TaskSampler(\n",
        "    train_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_tasks_per_epoch\n",
        ")\n",
        "val_sampler = TaskSampler(\n",
        "    val_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_validation_tasks\n",
        ")\n",
        "\n",
        "# Finally, the DataLoader. We customize the collate_fn so that batches are delivered\n",
        "# in the shape: (support_images, support_labels, query_images, query_labels, class_ids)\n",
        "train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_sampler=train_sampler,\n",
        "    num_workers=n_workers,\n",
        "    pin_memory=True,\n",
        "    collate_fn=train_sampler.episodic_collate_fn,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_set,\n",
        "    batch_sampler=val_sampler,\n",
        "    num_workers=n_workers,\n",
        "    pin_memory=True,\n",
        "    collate_fn=val_sampler.episodic_collate_fn,\n",
        ")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6gd9T0_DqCb",
        "outputId": "c858c812-b0a8-49dd-a8db-8379f08bf72a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then we define the network. Here I chose Prototypical Networks and the built-in ResNet18 from PyTorch because it's easy."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "dgGqqwuoDqCb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "source": [
        "from easyfsl.methods import PrototypicalNetworks, FewShotClassifier\n",
        "from easyfsl.modules import resnet12\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "convolutional_network = resnet12()\n",
        "few_shot_classifier = PrototypicalNetworks(convolutional_network).to(DEVICE)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rPNZzp5XDqCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's define our training helpers ! I chose to use Stochastic Gradient Descent on 200 epochs with a scheduler that divides the learning rate by 10 after 120 and 160 epochs. The strategy is derived from [this repo](https://github.com/fiveai/on-episodes-fsl).\n",
        "\n",
        "We're also gonna use a TensorBoard because it's always good to see what your training curves look like."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "_UyFFtvxDqCb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "source": [
        "from torch.optim import SGD, Optimizer\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 150\n",
        "scheduler_milestones = [100, 130]\n",
        "scheduler_gamma = 0.1\n",
        "learning_rate = 1e-2\n",
        "tb_logs_dir = Path(\".\")\n",
        "\n",
        "train_optimizer = SGD(\n",
        "    few_shot_classifier.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4\n",
        ")\n",
        "train_scheduler = MultiStepLR(\n",
        "    train_optimizer,\n",
        "    milestones=scheduler_milestones,\n",
        "    gamma=scheduler_gamma,\n",
        ")\n",
        "\n",
        "tb_writer = SummaryWriter(log_dir=str(tb_logs_dir))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gA7cyjkKDqCc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now let's get to it! Here we define the function that performs a training epoch.\n",
        "\n",
        "We use tqdm to monitor the training in real time in our logs."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "IGqZp-_uDqCc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [],
      "source": [
        "def training_epoch(\n",
        "    model: FewShotClassifier, data_loader: DataLoader, optimizer: Optimizer\n",
        "):\n",
        "    all_loss = []\n",
        "    model.train()\n",
        "    with tqdm(\n",
        "        enumerate(data_loader), total=len(data_loader), desc=\"Training\"\n",
        "    ) as tqdm_train:\n",
        "        for episode_index, (\n",
        "            support_images,\n",
        "            support_labels,\n",
        "            query_images,\n",
        "            query_labels,\n",
        "            _,\n",
        "        ) in tqdm_train:\n",
        "            optimizer.zero_grad()\n",
        "            model.process_support_set(\n",
        "                support_images.to(DEVICE), support_labels.to(DEVICE)\n",
        "            )\n",
        "            classification_scores = model(query_images.to(DEVICE))\n",
        "\n",
        "            loss = LOSS_FUNCTION(classification_scores, query_labels.to(DEVICE))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            all_loss.append(loss.item())\n",
        "\n",
        "            tqdm_train.set_postfix(loss=mean(all_loss))\n",
        "\n",
        "    return mean(all_loss)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "l4MHUy2_DqCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we have everything we need! To perform validations we'll just use the built-in `evaluate` function from `easyfsl.methods.utils`.\n",
        "\n",
        "This is now the time to **start training**.\n",
        "\n",
        "I added something to log the state of the model that gave the best performance on the validation set."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "LfQL7-50DqCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mv data/mini_imagenet/images data/mini_imagenet/data"
      ],
      "metadata": {
        "id": "TS9NI1j-HscE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 700/700 [04:57<00:00,  2.35it/s, loss=1.32]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [01:04<00:00,  3.12it/s, accuracy=0.44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 700/700 [05:02<00:00,  2.31it/s, loss=1.12]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [01:08<00:00,  2.94it/s, accuracy=0.463]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 700/700 [05:03<00:00,  2.30it/s, loss=1.01]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [01:05<00:00,  3.06it/s, accuracy=0.537]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 700/700 [05:04<00:00,  2.30it/s, loss=0.93]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [01:06<00:00,  3.02it/s, accuracy=0.552]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 700/700 [05:02<00:00,  2.31it/s, loss=0.863]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [01:04<00:00,  3.08it/s, accuracy=0.58]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 700/700 [05:03<00:00,  2.30it/s, loss=0.812]\n",
            "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [01:05<00:00,  3.06it/s, accuracy=0.613]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ding ding ding! We found a new best model!\n",
            "Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 302/700 [02:13<02:49,  2.35it/s, loss=0.752]"
          ]
        }
      ],
      "source": [
        "# from easyfsl.utils import evaluate\n",
        "\n",
        "\n",
        "# best_state = few_shot_classifier.state_dict()\n",
        "# best_validation_accuracy = 0.0\n",
        "# for epoch in range(n_epochs):\n",
        "#     print(f\"Epoch {epoch}\")\n",
        "#     average_loss = training_epoch(few_shot_classifier, train_loader, train_optimizer)\n",
        "#     validation_accuracy = evaluate(\n",
        "#         few_shot_classifier, val_loader, device=DEVICE, tqdm_prefix=\"Validation\"\n",
        "#     )\n",
        "\n",
        "#     if validation_accuracy > best_validation_accuracy:\n",
        "#         best_validation_accuracy = validation_accuracy\n",
        "#         best_state = copy.deepcopy(few_shot_classifier.state_dict())\n",
        "#         # state_dict() returns a reference to the still evolving model's state so we deepcopy\n",
        "#         # https://pytorch.org/tutorials/beginner/saving_loading_models\n",
        "#         print(\"Ding ding ding! We found a new best model!\")\n",
        "\n",
        "#     tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n",
        "#     tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n",
        "\n",
        "#     # Warn the scheduler that we did an epoch\n",
        "#     # so it knows when to decrease the learning rate\n",
        "#     train_scheduler.step()\n",
        "# from easyfsl.utils import evaluate\n",
        "# import copy\n",
        "# import torch\n",
        "# import os\n",
        "\n",
        "# # --- 1. MOUNT GOOGLE DRIVE (Run this cell once before the loop) ---\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# CHECKPOINT_DIR = '/content/drive/MyDrive/miniimagenet_checkpoints/'\n",
        "# # Create the checkpoint directory if it doesn't exist\n",
        "# os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "# # ---------------------------------------------------------------------\n",
        "\n",
        "# best_state = few_shot_classifier.state_dict()\n",
        "# best_validation_accuracy = 0.0\n",
        "\n",
        "# # Assume DEVICE, n_epochs, training_epoch, train_loader, val_loader,\n",
        "# # train_optimizer, tb_writer, and train_scheduler are defined previously\n",
        "\n",
        "# for epoch in range(n_epochs):\n",
        "#     print(f\"Epoch {epoch}\")\n",
        "#     average_loss = training_epoch(few_shot_classifier, train_loader, train_optimizer)\n",
        "#     validation_accuracy = evaluate(\n",
        "#         few_shot_classifier, val_loader, device=DEVICE, tqdm_prefix=\"Validation\"\n",
        "#     )\n",
        "\n",
        "#     if validation_accuracy > best_validation_accuracy:\n",
        "#         best_validation_accuracy = validation_accuracy\n",
        "#         best_state = copy.deepcopy(few_shot_classifier.state_dict())\n",
        "#         print(\"Ding ding ding! We found a new best model!\")\n",
        "\n",
        "#         # --- SAVE THE BEST MODEL ANYTIME IT IMPROVES ---\n",
        "#         best_checkpoint = {\n",
        "#             'epoch': epoch,\n",
        "#             'model_state_dict': few_shot_classifier.state_dict(),\n",
        "#             'optimizer_state_dict': train_optimizer.state_dict(),\n",
        "#             'best_validation_accuracy': best_validation_accuracy\n",
        "#         }\n",
        "#         torch.save(best_checkpoint, os.path.join(CHECKPOINT_DIR, 'best_model.pth'))\n",
        "\n",
        "\n",
        "#     # --- 2. SAVE CHECKPOINT EVERY 10TH EPOCH ---\n",
        "#     if (epoch + 1) % 10 == 0:\n",
        "#         checkpoint = {\n",
        "#             'epoch': epoch,\n",
        "#             'model_state_dict': few_shot_classifier.state_dict(),\n",
        "#             'optimizer_state_dict': train_optimizer.state_dict(),\n",
        "#             'best_validation_accuracy': best_validation_accuracy\n",
        "#         }\n",
        "#         checkpoint_path = os.path.join(CHECKPOINT_DIR, f'epoch_{epoch+1}.pth')\n",
        "#         torch.save(checkpoint, checkpoint_path)\n",
        "#         print(f\"Checkpoint saved at epoch {epoch+1} to {checkpoint_path}\")\n",
        "#     # -----------------------------------------------\n",
        "\n",
        "#     tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n",
        "#     tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n",
        "\n",
        "#     train_scheduler.step()\n",
        "\n",
        "from easyfsl.utils import evaluate\n",
        "import copy\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# --- 1. MOUNT GOOGLE DRIVE (Run this cell once before the loop) ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/miniimagenet_checkpoints/'\n",
        "# Create the checkpoint directory if it doesn't exist\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "# Assume model, optimizer, etc., are initialized here (or loaded from a previous checkpoint)\n",
        "# Note: Variables like few_shot_classifier, train_optimizer, etc., must be defined\n",
        "# before this block runs.\n",
        "\n",
        "best_state = few_shot_classifier.state_dict()\n",
        "best_validation_accuracy = 0.0\n",
        "\n",
        "# --- Function for Atomic Save ---\n",
        "def save_atomic(state, final_path):\n",
        "    \"\"\"Saves the checkpoint safely using a temporary file to prevent corruption.\"\"\"\n",
        "    temp_path = final_path + \".tmp\"\n",
        "\n",
        "    # 1. Save to the temporary location\n",
        "    torch.save(state, temp_path)\n",
        "\n",
        "    # 2. Rename the temporary file to the final path (atomic operation)\n",
        "    os.rename(temp_path, final_path)\n",
        "# ----------------------------------\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    average_loss = training_epoch(few_shot_classifier, train_loader, train_optimizer)\n",
        "    validation_accuracy = evaluate(\n",
        "        few_shot_classifier, val_loader, device=DEVICE, tqdm_prefix=\"Validation\"\n",
        "    )\n",
        "\n",
        "    if validation_accuracy > best_validation_accuracy:\n",
        "        best_validation_accuracy = validation_accuracy\n",
        "        best_state = copy.deepcopy(few_shot_classifier.state_dict())\n",
        "        print(\"Ding ding ding! We found a new best model!\")\n",
        "\n",
        "        # --- SAVE THE BEST MODEL ATOMICALLY ---\n",
        "        best_checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': few_shot_classifier.state_dict(),\n",
        "            'optimizer_state_dict': train_optimizer.state_dict(),\n",
        "            'best_validation_accuracy': best_validation_accuracy\n",
        "        }\n",
        "        final_best_path = os.path.join(CHECKPOINT_DIR, 'best_model.pth')\n",
        "        save_atomic(best_checkpoint, final_best_path)\n",
        "        print(\"Best checkpoint saved safely.\")\n",
        "\n",
        "\n",
        "    # --- SAVE PERIODIC CHECKPOINT ATOMICALLY ---\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': few_shot_classifier.state_dict(),\n",
        "            'optimizer_state_dict': train_optimizer.state_dict(),\n",
        "            'best_validation_accuracy': best_validation_accuracy\n",
        "        }\n",
        "        checkpoint_path = os.path.join(CHECKPOINT_DIR, f'epoch_{epoch+1}.pth')\n",
        "        save_atomic(checkpoint, checkpoint_path)\n",
        "        print(f\"Periodic checkpoint saved safely at epoch {epoch+1}.\")\n",
        "    # -----------------------------------------------\n",
        "\n",
        "    tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n",
        "    tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n",
        "\n",
        "    train_scheduler.step()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZhy03VsDqCd",
        "outputId": "8d7d35ae-1a10-442a-c436-c1bfa3668eae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReTraining"
      ],
      "metadata": {
        "id": "IvxZJ5y3PSML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, os, tempfile\n",
        "\n",
        "def save_atomic(state, final_path):\n",
        "    \"\"\"Write checkpoint atomically and safely (no corruption).\"\"\"\n",
        "    os.makedirs(os.path.dirname(final_path), exist_ok=True)\n",
        "\n",
        "    # Save to temp file in same directory\n",
        "    with tempfile.NamedTemporaryFile(dir=os.path.dirname(final_path), delete=False) as tmp_file:\n",
        "        temp_path = tmp_file.name\n",
        "        torch.save(state, temp_path)\n",
        "\n",
        "    # Atomic replace\n",
        "    os.replace(temp_path, final_path)\n"
      ],
      "metadata": {
        "id": "dz-VNBPEP9ID"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h_CmgTM2Wlls",
        "outputId": "e12be2d8-ba7a-449c-dd24-d39f8b6574ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/easy-few-shot-learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import copy\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "CHECKPOINT_DIR = '/content/'\n",
        "CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, 'best_model.pth')\n",
        "\n",
        "NEW_BASE_LEARNING_RATE = 1e-4\n",
        "NEW_SCHEDULER_MILESTONES = [60, 100]\n",
        "\n",
        "best_validation_accuracy = 0.0\n",
        "start_epoch = 0\n",
        "\n",
        "# ---------------- RESUME IF POSSIBLE ----------------\n",
        "if os.path.exists(CHECKPOINT_PATH):\n",
        "    print(f\"Loading checkpoint: {CHECKPOINT_PATH}\")\n",
        "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
        "\n",
        "    # Load model\n",
        "    few_shot_classifier.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    # Load optimizer\n",
        "    train_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    # Restore accuracy + epoch\n",
        "    best_validation_accuracy = checkpoint.get('best_validation_accuracy', 0.0)\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "\n",
        "    # ----- SAFELY UPDATE LR AFTER RESUME -----\n",
        "    for pg in train_optimizer.param_groups:\n",
        "        pg[\"lr\"] = NEW_BASE_LEARNING_RATE\n",
        "\n",
        "    # ----- SAFELY UPDATE SCHEDULER -----\n",
        "    train_scheduler.milestones = NEW_SCHEDULER_MILESTONES\n",
        "    train_scheduler.last_epoch = start_epoch - 1\n",
        "\n",
        "    print(f\"RESUME SUCCESS: start_epoch={start_epoch}, best_acc={best_validation_accuracy:.4f}\")\n",
        "else:\n",
        "    print(\"No checkpoint found, starting fresh.\")\n"
      ],
      "metadata": {
        "id": "cj1tJktRbJ9i",
        "outputId": "49fc29e6-5774-4ef3-df7d-81d6055e90bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint: /content/best_model.pth\n",
            "RESUME SUCCESS: start_epoch=11, best_acc=0.6616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from easyfsl.utils import evaluate\n",
        "import copy\n",
        "import torch\n",
        "import os\n",
        "for epoch in range(start_epoch, n_epochs):\n",
        "    print(f\"\\nEpoch {epoch}\")\n",
        "\n",
        "    average_loss = training_epoch(\n",
        "        few_shot_classifier, train_loader, train_optimizer\n",
        "    )\n",
        "    validation_accuracy = evaluate(\n",
        "        few_shot_classifier, val_loader, device=DEVICE, tqdm_prefix=\"Validation\"\n",
        "    )\n",
        "\n",
        "    # ---------------- SAVE BEST MODEL ----------------\n",
        "    if validation_accuracy > best_validation_accuracy:\n",
        "        best_validation_accuracy = validation_accuracy\n",
        "        print(f\"ðŸ”¥ New best model found (Acc={validation_accuracy:.4f})\")\n",
        "\n",
        "        best_checkpoint = {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": few_shot_classifier.state_dict(),\n",
        "            \"optimizer_state_dict\": train_optimizer.state_dict(),\n",
        "            \"scheduler_state_dict\": train_scheduler.state_dict(),\n",
        "            \"best_validation_accuracy\": best_validation_accuracy,\n",
        "        }\n",
        "\n",
        "        final_best_path = os.path.join(CHECKPOINT_DIR, \"best_model.pth\")\n",
        "        save_atomic(best_checkpoint, final_best_path)\n",
        "        print(\"Best model saved atomically.\")\n",
        "\n",
        "    # ---------------- PERIODIC CHECKPOINT ----------------\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        ckpt_path = os.path.join(CHECKPOINT_DIR, f\"epoch_{epoch+1}.pth\")\n",
        "        checkpoint = {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": few_shot_classifier.state_dict(),\n",
        "            \"optimizer_state_dict\": train_optimizer.state_dict(),\n",
        "            \"scheduler_state_dict\": train_scheduler.state_dict(),\n",
        "            \"best_validation_accuracy\": best_validation_accuracy,\n",
        "        }\n",
        "        save_atomic(checkpoint, ckpt_path)\n",
        "        print(f\"Checkpoint saved at epoch {epoch+1}.\")\n",
        "\n",
        "    # ---------------- LOGGING ----------------\n",
        "    tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n",
        "    tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n",
        "\n",
        "    # ---------------- LR STEP ----------------\n",
        "    train_scheduler.step()\n"
      ],
      "metadata": {
        "id": "NdQMRVDXbSa5",
        "outputId": "ef0e2b02-3c2c-42be-caad-71e698b82925",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 434/700 [03:09<01:51,  2.38it/s, loss=0.567]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "GYX_6UviDqCf"
      },
      "source": [
        "Yay we successfully performed Episodic Training! Now if you want to you can retrieve the best model's state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tZS7-JtVDqCf"
      },
      "outputs": [],
      "source": [
        "few_shot_classifier.load_state_dict(best_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "B-d9GdLfDqCf"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Now that our model is trained, we want to test it.\n",
        "\n",
        "First step: we fetch the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iOgYl0eLDqCf"
      },
      "outputs": [],
      "source": [
        "n_test_tasks = 1000\n",
        "\n",
        "test_set = CUB(split=\"test\", training=False)\n",
        "test_sampler = TaskSampler(\n",
        "    test_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_test_tasks\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_set,\n",
        "    batch_sampler=test_sampler,\n",
        "    num_workers=n_workers,\n",
        "    pin_memory=True,\n",
        "    collate_fn=test_sampler.episodic_collate_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "R5bBjULiDqCf"
      },
      "source": [
        "Second step: we run the few-shot classifier on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "y4ZtMBm4DqCg"
      },
      "outputs": [],
      "source": [
        "accuracy = evaluate(few_shot_classifier, test_loader, device=DEVICE)\n",
        "print(f\"Average accuracy : {(100 * accuracy):.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-rYytaJ7DqCh"
      },
      "source": [
        "Congrats! You performed Episodic Training using EasyFSL. If you want to compare with a model trained using classical training, look at [this other example notebook](classical_training.ipynb).\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "episodic_training.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}